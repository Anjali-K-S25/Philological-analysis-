{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anjali-K-S25/Philological-analysis-/blob/main/PatuAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "hHqTZARb-54n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SToYCZsyl2o",
        "outputId": "ddd2e0de-4073-4912-b000-b4c2f732d55d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P73GoghrywJP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from transformers import MarianMTModel, MarianTokenizer, pipeline, BartForConditionalGeneration, BartTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGopktEJy3lo"
      },
      "outputs": [],
      "source": [
        "# Synthetic dataset: Sanskrit and Proto-Dravidian sentences (10 each)\n",
        "texts = [\n",
        "    # Sanskrit sentences\n",
        "    \"रामः वनं गच्छति\",\"अहम् पाठशालां गच्छामि\", \"सीता फलम् खादति\",\n",
        "    \"शिवः तत्र स्थितः\", \"गुरुः पाठयति\", \"अहम् पठामि\", \"बालकः खेलति\", \"अहम् पठामि पुस्तकं\", \"रामस्य मित्रः आगच्छति\", \"सीता गीतं गायति\",\n",
        "\n",
        "    # Proto-Dravidian-inspired sentences (synthetic)\n",
        "    \"நான் பள்ளிக்குச் செல்வேன்\", \"அவன் ஓடுகிறான்\", \"நான் புத்தகம் படிக்கிறேன்\",\n",
        "    \"அவள் பாடம் படிக்கிறாள்\", \"நாம் வீட்டிற்கு செல்கிறோம்\", \"அவர் பாடம் கற்றுக்கொள்கிறார்\", \"நான் ஓடுகிறேன்\", \"அவர் பாடம் படிக்கிறார்\", \"நான் உணவு சாப்பிடுகிறேன்\", \"அவன் விளையாடுகிறான்\"\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    # Sanskrit labels\n",
        "    \"Sanskrit\", \"Sanskrit\", \"Sanskrit\", \"Sanskrit\", \"Sanskrit\", \"Sanskrit\", \"Sanskrit\", \"Sanskrit\", \"Sanskrit\", \"Sanskrit\",\n",
        "\n",
        "    # Proto-Dravidian labels\n",
        "    \"Proto-Dravidian\", \"Proto-Dravidian\", \"Proto-Dravidian\", \"Proto-Dravidian\", \"Proto-Dravidian\", \"Proto-Dravidian\", \"Proto-Dravidian\", \"Proto-Dravidian\", \"Proto-Dravidian\", \"Proto-Dravidian\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fGY_N13y6zt"
      },
      "outputs": [],
      "source": [
        "# Translation function (Sanskrit/Proto-Dravidian → English)\n",
        "def translate_text(text, model_name=\"Helsinki-NLP/opus-mt-hi-en\"):\n",
        "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "    model = MarianMTModel.from_pretrained(model_name)\n",
        "    inputs = tokenizer([text], return_tensors=\"pt\", padding=True)\n",
        "    translated = model.generate(**inputs)\n",
        "    return tokenizer.decode(translated[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDw4T_q9y9Nn"
      },
      "outputs": [],
      "source": [
        "# NLP analysis: NER + Sentiment\n",
        "def analyze_text(text):\n",
        "    nlp_ner = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
        "    sentiment = pipeline(\"sentiment-analysis\")\n",
        "    entities = nlp_ner(text)\n",
        "    sentiment_result = sentiment(text)\n",
        "    return {\"entities\": entities, \"sentiment\": sentiment_result}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkpfn8MOzAEb"
      },
      "outputs": [],
      "source": [
        "# Text restoration\n",
        "def restore_text(partial_text, model_name=\"facebook/bart-base\"):\n",
        "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "    inputs = tokenizer([partial_text], return_tensors=\"pt\", padding=True)\n",
        "    outputs = model.generate(inputs[\"input_ids\"], max_length=100, num_beams=5, early_stopping=True)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_feqS0-zDgr"
      },
      "outputs": [],
      "source": [
        "# Stylometry with multiple algorithms + epochs + cross-validation\n",
        "def stylometry_multi_algo(texts, labels, test_text, epochs=50):\n",
        "    vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
        "    X = vectorizer.fit_transform(texts)\n",
        "    y = labels\n",
        "    X_test = vectorizer.transform([test_text])\n",
        "    results = {}\n",
        "\n",
        "    rf_clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "    rf_clf.fit(X, y)\n",
        "    rf_pred = rf_clf.predict(X_test)[0]\n",
        "    rf_acc = np.mean(cross_val_score(rf_clf, X, y, cv=5))\n",
        "    results[\"RandomForest\"] = {\"prediction\": rf_pred, \"CV_accuracy\": rf_acc}\n",
        "\n",
        "    svm_clf = SVC(kernel=\"linear\", probability=True)\n",
        "    svm_clf.fit(X, y)\n",
        "    svm_pred = svm_clf.predict(X_test)[0]\n",
        "    svm_acc = np.mean(cross_val_score(svm_clf, X, y, cv=5))\n",
        "    results[\"SVM\"] = {\"prediction\": svm_pred, \"CV_accuracy\": svm_acc}\n",
        "\n",
        "    log_clf = LogisticRegression(max_iter=epochs, solver='lbfgs', multi_class='auto')\n",
        "    log_clf.fit(X, y)\n",
        "    log_pred = log_clf.predict(X_test)[0]\n",
        "    log_acc = np.mean(cross_val_score(log_clf, X, y, cv=5))\n",
        "    results[\"LogisticRegression\"] = {\"prediction\": log_pred, \"CV_accuracy\": log_acc}\n",
        "\n",
        "    mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=epochs, random_state=42)\n",
        "    mlp_clf.fit(X, y)\n",
        "    mlp_pred = mlp_clf.predict(X_test)[0]\n",
        "    mlp_acc = np.mean(cross_val_score(mlp_clf, X, y, cv=5))\n",
        "    results[\"MLPClassifier\"] = {\"prediction\": mlp_pred, \"CV_accuracy\": mlp_acc}\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwiJNrs-zGtd",
        "outputId": "fdf12caa-cbc3-44a3-fe2f-0b114b013b9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated Text: Ram: School's high\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n",
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entities: []\n",
            "Sentiment: [{'label': 'NEGATIVE', 'score': 0.970949113368988}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest: Prediction = Sanskrit, CV Accuracy = 60.0%\n",
            "SVM: Prediction = Sanskrit, CV Accuracy = 85.0%\n",
            "LogisticRegression: Prediction = Sanskrit, CV Accuracy = 70.0%\n",
            "MLPClassifier: Prediction = Sanskrit, CV Accuracy = 85.0%\n",
            "Restored Text: रामः ... गच्छति\n"
          ]
        }
      ],
      "source": [
        "# Example test text (Sanskrit)\n",
        "test_text = \"रामः पाठशालां गच्छति\"\n",
        "# Translation\n",
        "translated = translate_text(test_text)\n",
        "print(\"Translated Text:\", translated)\n",
        "# NLP Analysis\n",
        "analysis = analyze_text(translated)\n",
        "print(\"Named Entities:\", analysis[\"entities\"])\n",
        "print(\"Sentiment:\", analysis[\"sentiment\"])\n",
        "# Stylometry predictions\n",
        "results = stylometry_multi_algo(texts, labels, test_text, epochs=100)\n",
        "for algo, info in results.items():\n",
        "    print(f\"{algo}: Prediction = {info['prediction']}, CV Accuracy = {round(info['CV_accuracy']*100,2)}%\")\n",
        "# Restoration example\n",
        "damaged_text = \"रामः ... गच्छति\"\n",
        "restored = restore_text(damaged_text)\n",
        "print(\"Restored Text:\", restored)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQNfG2hONEEXcunZcuj88P",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}